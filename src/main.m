% Fit a TM to some artificially generated data
% NB: Don't forget to add minFunc to your matlab path if you use it as the solver
clear all; clc;

addpath('../datasets/')
%'forest_small' is generated by randomly selecting 50000 examples from the original 'forest' 
%training set (the test set remains unchanged) hence the resulting test error here might be higher than the one reported in the paper.
load forest_small
%load adult
type = 'bc'; % binary classification

% preprocessing impacts the performance of TMs
preproc_data

% setting parameters
q = 4; % degree 
%solver = 'minFunc'; % use lbfgs solver (TM-Batch)
solver = 'sfo'; % use SFO solver (TM-SFO)
maxIter = 15; % number of iterations of the solver
verbosity = 'minimal';

% cross-validation ranges
alpha_range = [0.01,0.1]; % the norm of the random points used to initialize the TM parameters
lambdarange = [1e-8,1e-6,1e-4,1e-2]; % the regularization constant
rrange = [3,4,5,6]; % rank parameter

% use cross validation on the training data to calculate errors and standard deviations
% the three dimensions of err and err_std correspond to alpha, lambda and rank, respectively.
[err,err_std] = cv_tensor_machines(X, Y, type, alpha_range, lambdarange, rrange, solver, q, maxIter, verbosity);

%call tensor machines using the best parameters from cross validation
options.q = q;
options.solver = solver;
options.maxIter = maxIter;
options.verbosity = verbosity;

[i,j,k] = ind2sub(size(err), find(err == min(err(:))));
options.alpha = alpha_range(i);
options.lambda = lambdarange(j);
options.r = rrange(k);
options.maxIter = maxIter*2; % run it for longer

% fit a TM: return its parameters and the test and train errors
[error_test, error_train, solver_outputs, opt_outputs] = tm_solver(X, Y, Xt, Yt, type, options);
fprintf('training error is %f\n', error_train)
fprintf('test error is %f\n', error_test)
fprintf('training time is %f (s)\n', solver_outputs.time_train)
fprintf('test time is %f (s)\n', solver_outputs.time_test)

